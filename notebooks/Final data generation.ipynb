{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61110ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRECTORIES\n",
    "\n",
    "RealImagesDir = \"/mnt/DADES2/STELA/data\"\n",
    "RealImagesJsonDir = \"/mnt/DADES2/STELA/data/STELA_DATASET.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b26ce-c521-4742-a186-6cd962ee6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel,UniPCMultistepScheduler\n",
    "import torch\n",
    "import string\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import NewPal as ft\n",
    "import json\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8816573-3c17-496e-a159-00a901519bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # You can change the index if you have more GPUs\n",
    "    print(\"CUDA Device Name:\", torch.cuda.get_device_name(device))\n",
    "    print(\"Memoria Total (MB):\", torch.cuda.get_device_properties(0).total_memory // (1024 ** 2))\n",
    "else:\n",
    "    print(\"No CUDA device available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86496e71-ee44-4355-94d2-5fcdabb4e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "def image_grid(imgs, prompt_len):\n",
    "    # Calculate rows and columns dynamically based on the length of the prompt\n",
    "    cols = 2  # Adjust number of columns as needed\n",
    "    rows = (prompt_len + cols - 1) // cols  # Compute number of rows\n",
    "\n",
    "    assert len(imgs) == prompt_len\n",
    "\n",
    "    # Create a new figure to plot the images\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))  # Adjust size if needed\n",
    "\n",
    "    # If only one row or one column, axes will not be an array\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        # Convert numpy array to Image if needed\n",
    "        if isinstance(img, np.ndarray):\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "        # Plot image on the corresponding axis\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis(\"off\")  # Hide axis for better visualization\n",
    "        axes[i].set_title(f\"Image {i+1}\")  # Optional: Set title for each image\n",
    "\n",
    "    # Turn off axes for any remaining empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    # Adjust layout to avoid overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def drawText(string, x, y, ix, iy, scale, color, icolor, digit_spacing=15):\n",
    "    for i, c in enumerate(string):  \n",
    "        print(c)\n",
    "        ft.drawCode(c, x, y, scale, color, alpha = 0.5)\n",
    "        \n",
    "        # Determine spacing\n",
    "        extra_spacing = digit_spacing if c!=\" \" else 0\n",
    "        x += ix + ft.getCodeWidth(c, scale) + extra_spacing\n",
    "        y += iy\n",
    "\n",
    "        if icolor is not None:\n",
    "            color = tuple(np.array(color) + np.array(icolor))\n",
    "\n",
    "\n",
    "def add_spaces(text):\n",
    "    return ' '.join(list(text))\n",
    "\n",
    "def Image2Canny(image, drawing_region, code, font_scale, line_spacing=10):\n",
    "    # Mask the current ID code\n",
    "    polygon_points = [(x, y) for label, x, y in drawing_region]\n",
    "    mask = Image.new('L', image.size, 0) \n",
    "    ImageDraw.Draw(mask).polygon(polygon_points, fill=255)\n",
    "\n",
    "    image_rgb = image.convert(\"RGB\")\n",
    "    blurred_image = image_rgb.filter(ImageFilter.GaussianBlur(radius=15))  \n",
    "    final_image = Image.composite(blurred_image, image_rgb, mask)\n",
    "    image_np = np.array(final_image)\n",
    "\n",
    "    # Text drawing setup\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    thickness = 2\n",
    "    text_color = (255, 255, 255)\n",
    "\n",
    "    (x0, y0) = (drawing_region[0][1], drawing_region[0][2])\n",
    "    (x2, y2) = (drawing_region[2][1], drawing_region[2][2])\n",
    "    region_width = x2 - x0\n",
    "    region_height = y2 - y0\n",
    "\n",
    "    # Add spaces between chars in each line\n",
    "    code_lines = [add_spaces(line) for line in code.split('\\n')]\n",
    "    \n",
    "    (text_width, text_height), baseline = cv2.getTextSize(code_lines[0], font, font_scale, thickness)\n",
    "    \n",
    "    total_text_height = len(code_lines) * (text_height + baseline + line_spacing) - line_spacing\n",
    "    y_start = y0 + (region_height - total_text_height) // 2 + text_height\n",
    "\n",
    "    for i, line in enumerate(code_lines):\n",
    "        (line_width, _), _ = cv2.getTextSize(line, font, font_scale, thickness)\n",
    "        x = x0 + (region_width - line_width) // 2\n",
    "        y = y_start + i * (text_height + baseline + line_spacing)\n",
    "        cv2.putText(image_np, line, (x, y), font, font_scale, text_color, thickness, cv2.LINE_AA)\n",
    "       \n",
    "    gray_with_text = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n",
    "    canny_result = cv2.Canny(gray_with_text, threshold1=10, threshold2=80)\n",
    "    final_edge_image = Image.fromarray(canny_result).convert(\"RGB\")\n",
    "\n",
    "    return image, final_image, final_edge_image\n",
    "\n",
    "\n",
    "# READ DATA\n",
    "\n",
    "try:\n",
    "    with open(RealImagesJsonDir, \"r\") as f: \n",
    "        Annotations = json.load(f)\n",
    "        i = len(Annotations)\n",
    "        print(\"JSON file loaded successfully.\")\n",
    "        print(f\"Number of entries: {i}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"JSON file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45242822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CannyCode(code, x, y, mask_size, scale=1.0, digit_spacing=5):\n",
    "    \"\"\"\n",
    "    Draws text with soft blur and applies a Canny edge detector.\n",
    "    \n",
    "    Parameters:\n",
    "    - code: str - The text code to render\n",
    "    - x, y: int - Starting position for the text\n",
    "    - mask_size: (width, height) - Size of the blank mask\n",
    "    - scale: float - Text scale (default 1.0)\n",
    "    - digit_spacing: int - Extra spacing between digits\n",
    "    \"\"\"\n",
    "    def drawTextSoftBlur(string, x, y, ix, iy, scale, color, icolor, digit_spacing=5, canvas_shape=(512, 512)):\n",
    "        \"\"\"Draws bold text with soft blur, tracks character positions.\"\"\"\n",
    "\n",
    "        h, w = canvas_shape[:2]\n",
    "        drawn_chars = []  # ðŸŒ¸ We'll store [char, [x, y]] here\n",
    "\n",
    "        for i, c in enumerate(string):\n",
    "            code_width = ft.getCodeWidth(c, scale)\n",
    "            code_height = ft.getCodeHeight(c, scale) if hasattr(ft, \"getCodeHeight\") else 50 * scale\n",
    "\n",
    "            # Check bounds before drawing\n",
    "            if 0 <= x < w and 0 <= y < h and x + code_width < w and y + code_height < h:\n",
    "                ft.drawCode(c, x, y, scale, color, alpha=0.8)\n",
    "                ft.drawCode(c, x+1, y + 1, scale, color, alpha=0.8)\n",
    "                \n",
    "\n",
    "                # ðŸ’• Save character and bottom-left corner\n",
    "                if c != \" \":\n",
    "                    drawn_chars.append([c, int(x), int(y)])\n",
    "\n",
    "            extra_spacing = digit_spacing if c != \" \" else 0\n",
    "            x += ix + code_width + extra_spacing\n",
    "            y += iy\n",
    "\n",
    "            if icolor is not None:\n",
    "                color = tuple(np.clip(np.array(color) + np.array(icolor), 0, 255))\n",
    "\n",
    "        return drawn_chars\n",
    "\n",
    "\n",
    "        # Prepare mask\n",
    "    mask = np.zeros(mask_size, dtype=np.uint8)\n",
    "\n",
    "    # Prepare text lines\n",
    "    code_lines = [add_spaces(line) for line in code.split('\\n')]\n",
    "\n",
    "    # Drawing setup\n",
    "    color = (1, 1, 1)       # white ðŸ’®\n",
    "    icolor = (0, 0, 0)      # no inner color change\n",
    "    space = scale * -5 / 0.67\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), dpi=100)\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    ax.imshow(mask, cmap='gray', aspect='auto')\n",
    "    ax.axis('off')\n",
    "\n",
    "    cur_y = y\n",
    "    json_data = {\"chars\": [], \"code\": code, \"scale\": scale}\n",
    "\n",
    "    for line in code_lines:\n",
    "        chars = drawTextSoftBlur(line, x, cur_y, space, 0, scale, color, icolor, digit_spacing, canvas_shape=mask_size)\n",
    "        cur_y += scale * 80 / 1.08\n",
    "        json_data[\"chars\"].append(chars)\n",
    "\n",
    "    json_data[\"chars\"] = [item for sublist in json_data[\"chars\"] for item in sublist]\n",
    "\n",
    "    # Render and convert\n",
    "    fig.canvas.draw()\n",
    "    fused_img = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Image processing\n",
    "    fused_img = cv2.cvtColor(fused_img, cv2.COLOR_RGBA2BGR)\n",
    "    dilated_mask = cv2.dilate(fused_img, np.ones((3, 3), np.uint8), iterations=1)\n",
    "    canny_result = cv2.Canny(dilated_mask, threshold1=10, threshold2=80)\n",
    "\n",
    "    return canny_result, json_data\n",
    "\n",
    "def Image2Canny(image, drawing_region, code, font_scale, inside_polygon= True, digit_spacing=5, thresh1=10, thresh2=80, x_initial=None, y_initial=None, method= None):\n",
    "\n",
    "    # Mask the current ID code\n",
    "    polygon_points = [(x, y) for label, x, y in drawing_region]\n",
    "    mask = Image.new('L', image.size, 0) \n",
    "    ImageDraw.Draw(mask).polygon(polygon_points, fill=255)\n",
    "\n",
    "    # Apply Gaussian blur to the imag\n",
    "\n",
    "    image_rgb = image.convert(\"RGB\")\n",
    "\n",
    "    blurred_image = image_rgb.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "    \n",
    "    final_image = Image.composite(blurred_image, image_rgb, mask)\n",
    "    image_np = np.array(final_image)\n",
    "\n",
    "    # Background canny\n",
    "    gray_with_text = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n",
    "    canny_background = cv2.Canny(gray_with_text, threshold1=thresh1, threshold2=thresh2)\n",
    "    # Code canny\n",
    "    # compute x-initial and y-initial so it is centered in the polygon\n",
    "    if inside_polygon:\n",
    "\n",
    "        space = font_scale * - 5 / 0.67\n",
    "\n",
    "        code_lines = [add_spaces(line) for line in code.split('\\n')]\n",
    "        widths = []\n",
    "        for line in code_lines:\n",
    "            widths.append(sum(ft.getCodeWidth(c, font_scale) for c in line) + space * (len(line)))\n",
    "                \n",
    "        max_width = max(widths)\n",
    "    \n",
    "        if x_initial is None or y_initial is None:\n",
    "            # Center the code in the polygon\n",
    "            x_initial = int((drawing_region[0][1] + drawing_region[2][1]) / 2) - int(max_width/2)\n",
    "            y_initial = int((drawing_region[0][2] + drawing_region[2][2]) / 2) - int(font_scale * 80 / 1.08)\n",
    "\n",
    "    size = canny_background.shape[:2]\n",
    "    canny_code, json_data = CannyCode(code, x_initial, y_initial, size, scale=font_scale, digit_spacing=digit_spacing, defect_type=method)\n",
    "\n",
    "    # Control canny generation\n",
    "    canny_img = cv2.bitwise_or(canny_background, canny_code)\n",
    "    canny_img = Image.fromarray(canny_img).convert(\"RGB\")\n",
    "\n",
    "    return image, Image.fromarray(canny_background).convert(\"RGB\"), Image.fromarray(canny_code).convert(\"RGB\"), canny_img, json_data\n",
    "\n",
    "def generate_code_lines(num_lines=3, length=10, min_alpha=120):\n",
    "    # Get list of supported characters from ft.codes\n",
    "    available_chars = [chr(c) for c in sorted(ft.codes.keys())]\n",
    "\n",
    "    # Extract alphabets from available_chars (assuming you want A-Z, a-z) and not accents or special characters\n",
    "    alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    numbers = [str(i) for i in range(10)]\n",
    "    alphabets.extend(numbers)\n",
    "\n",
    "    non_alphabets = [c for c in available_chars if c not in alphabets]\n",
    "\n",
    "    lines = []\n",
    "    for _ in range(num_lines):\n",
    " \n",
    "        line_chars = [random.choice(alphabets) for _ in range(length - 1)]\n",
    "        line_chars.append(random.choice(non_alphabets))\n",
    "\n",
    "        # Shuffle so alphabets are not always at start\n",
    "        random.shuffle(line_chars)\n",
    "        lines.append(''.join(line_chars))\n",
    "\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def save_image(image, image_name, output_dir=\"/mnt/DADES/home/jgarcia/CODE/6) STYLE TRANSFER/Paper Figures\"):\n",
    "    \"\"\"\n",
    "    Save an image to the specified directory.\n",
    "    Args:\n",
    "        image (numpy.ndarray or PIL.Image): The image to save.\n",
    "        image_name (str): The name of the file to save the image as.\n",
    "        output_dir (str): The directory where the image will be saved.\n",
    "    \"\"\"\n",
    "    if isinstance(image, np.ndarray):\n",
    "        image = Image.fromarray(image)\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the image\n",
    "    image_path = os.path.join(output_dir, image_name)\n",
    "    image.save(image_path)\n",
    "    print(f\"Image saved to {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f696e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CannyCode(code, x, y, mask_size, scale=1.0, digit_spacing=5, defect_type=None):\n",
    "    \"\"\"\n",
    "    Draws text with soft blur and applies a Canny edge detector.\n",
    "    \n",
    "    Parameters:\n",
    "    - code: str - The text code to render\n",
    "    - x, y: int - Starting position for the text\n",
    "    - mask_size: (width, height) - Size of the blank mask\n",
    "    - scale: float - Text scale (default 1.0)\n",
    "    - digit_spacing: int - Extra spacing between digits\n",
    "    \"\"\"\n",
    "    def drawTextSoftBlur(string, x, y, ix, iy, scale, color, icolor, digit_spacing=5, canvas_shape=(512, 512)):\n",
    "        \"\"\"Draws bold text with soft blur, tracks character positions.\"\"\"\n",
    "\n",
    "        h, w = canvas_shape[:2]\n",
    "        drawn_chars = []  # ðŸŒ¸ We'll store [char, [x, y]] here\n",
    "\n",
    "        for i, c in enumerate(string):\n",
    "            code_width = ft.getCodeWidth(c, scale)\n",
    "            code_height = ft.getCodeHeight(c, scale) if hasattr(ft, \"getCodeHeight\") else 50 * scale\n",
    "\n",
    "            # Check bounds before drawing\n",
    "            if 0 <= x < w and 0 <= y < h and x + code_width < w and y + code_height < h:\n",
    "                ft.drawCode(c, x, y, scale, color, alpha=0.8)\n",
    "                ft.drawCode(c, x+1, y + 1, scale, color, alpha=0.8)\n",
    "\n",
    "                if defect_type == \"deflection\":\n",
    "                    ft.drawCode(c, x+12, y- 8, scale, color, alpha=0.8)\n",
    "\n",
    "\n",
    "                if defect_type == \"beam\":\n",
    "                    ft.drawCode(c, x+2, y, scale, color, alpha=0.8)\n",
    "                    ft.drawCode(c, x-2, y, scale, color, alpha=0.8)\n",
    "                    ft.drawCode(c, x+3, y, scale, color, alpha=0.8)\n",
    "                    ft.drawCode(c, x-3, y, scale, color, alpha=0.8)\n",
    "                    ft.drawCode(c, x, y+2, scale, color, alpha=0.8)\n",
    "                    ft.drawCode(c, x, y-2, scale, color, alpha=0.8)\n",
    "\n",
    "                \n",
    "\n",
    "                # ðŸ’• Save character and bottom-left corner\n",
    "                if c != \" \":\n",
    "                    drawn_chars.append([c, int(x), int(y)])\n",
    "\n",
    "            extra_spacing = digit_spacing if c != \" \" else 0\n",
    "            x += ix + code_width + extra_spacing\n",
    "            y += iy\n",
    "\n",
    "            if icolor is not None:\n",
    "                color = tuple(np.clip(np.array(color) + np.array(icolor), 0, 255))\n",
    "\n",
    "        return drawn_chars\n",
    "\n",
    "\n",
    "        # Prepare mask\n",
    "    mask = np.zeros(mask_size, dtype=np.uint8)\n",
    "\n",
    "    # Prepare text lines\n",
    "    code_lines = [add_spaces(line) for line in code.split('\\n')]\n",
    "\n",
    "    # Drawing setup\n",
    "    color = (1, 1, 1)       # white ðŸ’®\n",
    "    icolor = (0, 0, 0)      # no inner color change\n",
    "    space = scale * -5 / 0.67\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), dpi=100)\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    ax.imshow(mask, cmap='gray', aspect='auto')\n",
    "    ax.axis('off')\n",
    "\n",
    "    cur_y = y\n",
    "    json_data = {\"chars\": [], \"code\": code, \"scale\": scale}\n",
    "\n",
    "    for line in code_lines:\n",
    "        chars = drawTextSoftBlur(line, x, cur_y, space, 0, scale, color, icolor, digit_spacing, canvas_shape=mask_size)\n",
    "        cur_y += scale * 80 / 1.08\n",
    "        json_data[\"chars\"].append(chars)\n",
    "\n",
    "    json_data[\"chars\"] = [item for sublist in json_data[\"chars\"] for item in sublist]\n",
    "\n",
    "    # Render and convert\n",
    "    fig.canvas.draw()\n",
    "    fused_img = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Image processing\n",
    "    fused_img = cv2.cvtColor(fused_img, cv2.COLOR_RGBA2BGR)\n",
    "    dilated_mask = cv2.dilate(fused_img, np.ones((3, 3), np.uint8), iterations=1)\n",
    "    canny_result = cv2.Canny(dilated_mask, threshold1=10, threshold2=80)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return canny_result, json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f663e-d0fe-4dc8-8f76-2dd43ba01c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLControlNetPipeline, ControlNetModel, AutoencoderKL\n",
    "from diffusers.utils import load_image\n",
    "from diffusers.image_processor import VaeImageProcessor\n",
    "\n",
    "class SD3CannyImageProcessor(VaeImageProcessor):\n",
    "    def __init__(self):\n",
    "        super().__init__(do_normalize=False)\n",
    "    def preprocess(self, image, **kwargs):\n",
    "        image = super().preprocess(image, **kwargs)\n",
    "        image = image * 255 * 0.5 + 0.5\n",
    "        return image\n",
    "    def postprocess(self, image, do_denormalize=True, **kwargs):\n",
    "        do_denormalize = [True] * image.shape[0]\n",
    "        image = super().postprocess(image, **kwargs, do_denormalize=do_denormalize)\n",
    "        return image\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "controlnet_path = \"/mnt/DADES/home/jgarcia/CODE/6) STYLE TRANSFER/ConrolNet Training/output\"\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    controlnet_path, torch_dtype=torch.float16\n",
    ")\n",
    "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
    "pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", controlnet=controlnet, vae=vae, torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "pipe.to(device)\n",
    "\n",
    "# pipe.enable_model_cpu_offload()\n",
    "# pipe.image_processor = SD3CannyImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = random.choice(list(Annotations.values()))\n",
    "file = entry[\"file\"]\n",
    "drawing_region = entry['reserve']\n",
    "original_scale = entry['scale']\n",
    "\n",
    "full_path = os.path.join(RealImagesDir, *file.split('\\\\'))\n",
    "original_img = Image.open(full_path)\n",
    "\n",
    "\n",
    "# emore conrtast\n",
    "plt.imshow(original_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_scale = 0.9 # original_scale\n",
    "thresh1 = 10\n",
    "thresh2 = 40\n",
    "\n",
    "digit_spacing = 2\n",
    "x_initial = 280\n",
    "y_initial = 250\n",
    "\n",
    "code = \"2R-01\\n22700\"\n",
    "image, background_canny, background_code, control_img, json_data = Image2Canny(original_img, drawing_region, code, font_scale, thresh1=thresh1, thresh2=thresh2, digit_spacing=digit_spacing, x_initial=x_initial, y_initial=y_initial, method = \"beam\")\n",
    "\n",
    "print(\"JSON Data:\", json_data)\n",
    "\n",
    "\n",
    "make_image_grid([image, background_canny, background_code, control_img], rows=1, cols=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_scale = 0.85 # original_scale\n",
    "thresh1 = 0\n",
    "thresh2 = 70\n",
    "digit_spacing = 2\n",
    "x_initial = 170\n",
    "y_initial = 300\n",
    "\n",
    "code = \"09/2023 H34:22 \\n L222 JULIA EPICA\" \n",
    "image, background_canny, background_code, control_img, json_data = Image2Canny(original_img, drawing_region, code, font_scale, thresh1=thresh1, thresh2=thresh2, digit_spacing=digit_spacing, x_initial=x_initial, y_initial=y_initial)\n",
    "\n",
    "control_img = np.array(control_img)\n",
    "x1, y1, x2, y2 =  drawing_region[0][1]+20, drawing_region[0][2]+20, drawing_region[2][1]-20, drawing_region[2][2]-20\n",
    "cv2.rectangle(control_img, (x1, y1), (x2, y2), color=(255, 255, 255), thickness=0)\n",
    "\n",
    "control_img = Image.fromarray(control_img).convert(\"RGB\")\n",
    "\n",
    "# overlay\n",
    "overlay_path = \"/mnt/DADES/home/jgarcia/CODE/6) STYLE TRANSFER/Creative Images/grietas-estructurales-en-edificios-1024x683-1.jpg\"\n",
    "overlay_img = cv2.imread(overlay_path)\n",
    "overlay_img = cv2.resize(overlay_img, (control_img.width, control_img.height))\n",
    "\n",
    "# draing region == overlay region square, else black\n",
    "drawing_region = [(label, x, y) for label, x, y in drawing_region]\n",
    "overlay_mask = np.zeros_like(overlay_img)\n",
    "polygon_points = np.array([(x, y) for label, x, y in drawing_region], dtype=np.int32)\n",
    "cv2.fillPoly(overlay_mask, [polygon_points], (255, 255, 255))   \n",
    "overlay_img = cv2.bitwise_and(overlay_img, overlay_mask)\n",
    "\n",
    "overlay_img = cv2.GaussianBlur(overlay_img, (7,7), 0)\n",
    "canny_overlay = cv2.Canny(overlay_img, threshold1=thresh1, threshold2=175)\n",
    "canny_overlay = Image.fromarray(canny_overlay).convert(\"RGB\")\n",
    "\n",
    "overlayed_image = cv2.bitwise_or(np.array(canny_overlay), np.array(control_img))\n",
    "print(\"JSON Data:\", json_data)\n",
    "\n",
    "overlayed_image = Image.fromarray(overlayed_image).convert(\"RGB\")\n",
    "make_image_grid([image, background_canny, background_code, control_img, canny_overlay, overlayed_image], rows=1, cols=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "\n",
    "    \"Grayscale close-up of a laser-printed label on industrial packaging.\"\n",
    ")\n",
    "\n",
    "num_gen_img = 1\n",
    "generated_imgs = pipe(\n",
    "    prompt, \n",
    "    image=control_img.convert(\"RGB\").resize((800, 800)), \n",
    "    num_inference_steps=20,\n",
    "    num_images_per_prompt=num_gen_img,\n",
    "    controlnet_conditioning_scale=1.2,\n",
    ").images\n",
    "\n",
    "\n",
    "for i in range(len(generated_imgs)):\n",
    "    generated_imgs[i] = generated_imgs[i].resize((800, 600), Image.LANCZOS)\n",
    "\n",
    "control_img = control_img.resize((800, 600), Image.LANCZOS)\n",
    "\n",
    "make_image_grid([original_img, control_img] + generated_imgs, rows=1, cols=num_gen_img + 2)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LoraEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
